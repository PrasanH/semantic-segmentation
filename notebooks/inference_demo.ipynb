{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e5a51eb",
   "metadata": {},
   "source": [
    "# DeepLabV3+ Transfer Learning Inference Demo\n",
    "\n",
    "DeepLabV3+ with interchangeable backbone transfer learning inference demo\n",
    "Net pretrained with COCO val2017, then trained with Yamaha-CMU Off-Road Dataset\n",
    "\n",
    "See: https://pytorch.org/hub/pytorch_vision_deeplabv3_resnet101/\n",
    "\n",
    "---\n",
    "\n",
    "Author: **Nate Haddad** nhaddad2112[at]gmail[dot]com"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "56f65e9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path as op\n",
    "import sys\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import yaml\n",
    "\n",
    "sys.path.append('..')\n",
    "from utils import vis_segmentation, display_example_pair, vis_grid_4x3, run_inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8298a608",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "10ebf6d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "03121bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../config/config.yaml', 'r') as f:\n",
    "    config = yaml.safe_load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55fd1f01",
   "metadata": {},
   "source": [
    "Visualize an example pair from the dataset. We will run inference on this image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf1e07b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = op.join('..', config['DATA_PATH'])\n",
    "example_image = Image.open(op.join(data_path, 'train/iid000008/rgb.jpg'))\n",
    "example_mask = Image.open(op.join(data_path, 'train/iid000008/labels.png'))\n",
    "image_display = np.array(example_image)\n",
    "mask_display = np.array(example_mask.convert('RGB'))\n",
    "display_example_pair(image_display, mask_display)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b05a956",
   "metadata": {},
   "source": [
    "Load a previously trained model and run the image through it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d4c45f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(op.join('..', config['LOAD_MODEL_PATH']))\n",
    "model.eval();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee691814",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = op.join('..', config['DATA_PATH'])\n",
    "example_image = Image.open(op.join(data_path, '2024-08-15_21-30-38_00000.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a65cd66",
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_masks = run_inference(model, example_image)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "403476a6",
   "metadata": {},
   "source": [
    "Finally, we take the orginal example image, and using the segmentation map, a custom color map for our labels, and the label names, overlay the segmentation map and create a key for each of the classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc95fb2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_segmentation(example_image, np.array(predicted_masks))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5abafb7",
   "metadata": {},
   "source": [
    "More example output, taken from our paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6805537f",
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_grid_4x3(model, data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "416b0d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from PIL import Image\n",
    "from utils import label_to_color_image\n",
    "\n",
    "with open('../config/config.yaml', 'r') as f:\n",
    "        config = yaml.safe_load(f)\n",
    "\n",
    "output_dir = r'H:\\segmentation_output'\n",
    "\n",
    "def generate_inference(config, output_dir):\n",
    "        model = torch.load(op.join('..', config['LOAD_MODEL_PATH']))\n",
    "        model.eval()\n",
    "        data_path = op.join('..', config['DATA_PATH'])\n",
    "        image_extensions = ('*.jpg', '*.jpeg', '*.png', '*.bmp', '*.gif', '*.tiff')\n",
    "        image_list = []\n",
    "        for ext in image_extensions:\n",
    "                image_list.extend(glob.glob(op.join(data_path, ext)))\n",
    "        for img_path in image_list:\n",
    "       \n",
    "                current_image = Image.open(img_path)\n",
    "                predicted_masks = run_inference(model, current_image)\n",
    "                #print(\"Predicted masks unique values:\", np.unique(predicted_masks))\n",
    "                \n",
    "                seg_img = get_seg_image(np.array(predicted_masks))\n",
    "        \n",
    "                # Construct output path and save the image\n",
    "                output_path = op.join(output_dir, op.basename(img_path))\n",
    "                seg_img = Image.fromarray(seg_img)\n",
    "                seg_img.save(output_path)\n",
    "                print(f\"Saved output to {output_path}\")\n",
    "\n",
    "def get_seg_image(seg_map):\n",
    "        label_names = np.asarray([\n",
    "                'non-traversable', 'rough trail', 'smooth trail', 'traversable grass',\n",
    "                'low vegetation', 'obstacle', 'high vegetation', 'sky'\n",
    "        ])\n",
    "        full_label_map = np.arange(len(label_names)).reshape(len(label_names), 1)\n",
    "        full_color_map = label_to_color_image(full_label_map)\n",
    "        seg_image = label_to_color_image(seg_map).astype(np.uint8)\n",
    "\n",
    "        return seg_image\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a9672fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### for unreal segmentation\n",
    "\n",
    "import glob\n",
    "from PIL import Image\n",
    "from utils import label_to_color_image\n",
    "\n",
    "with open('../config/config.yaml', 'r') as f:\n",
    "        config = yaml.safe_load(f)\n",
    "\n",
    "output_dir = '/home/pdhegde/semseg_git_fork/semantic-segmentation/out/'\n",
    "\n",
    "def generate_inference(config, output_dir):\n",
    "        model = torch.load(op.join('..', config['LOAD_MODEL_PATH']))\n",
    "        model.eval()\n",
    "        data_path = op.join('..', config['DATA_PATH'])\n",
    "        image_extensions = ('*.jpg', '*.jpeg', '*.png', '*.bmp', '*.gif', '*.tiff')\n",
    "        image_list = []\n",
    "        for ext in image_extensions:\n",
    "                image_list.extend(glob.glob(op.join(data_path, ext)))\n",
    "        for img_path in image_list:\n",
    "       \n",
    "                current_image = Image.open(img_path)\n",
    "                predicted_masks = run_inference(model, current_image)\n",
    "                #print(\"Predicted masks unique values:\", np.unique(predicted_masks))\n",
    "                \n",
    "                seg_img = get_seg_image(np.array(predicted_masks))\n",
    "        \n",
    "                # Construct output path and save the image\n",
    "                output_path = op.join(output_dir, op.basename(img_path))\n",
    "                seg_img = Image.fromarray(seg_img)\n",
    "                seg_img.save(output_path)\n",
    "                print(f\"Saved output to {output_path}\")\n",
    "\n",
    "def get_seg_image(seg_map):\n",
    "        label_names = np.asarray([\n",
    "                'sky', 'rock', 'vegetation', 'landscape_terrain',\n",
    "                'wall', 'vehicle', 'tree trunk', 'mountain', 'barn', 'building', 'roadside_object', 'unlabeled'\n",
    "        ])\n",
    "        full_label_map = np.arange(len(label_names)).reshape(len(label_names), 1)\n",
    "        full_color_map = label_to_color_image(full_label_map)\n",
    "        seg_image = label_to_color_image(seg_map).astype(np.uint8)\n",
    "\n",
    "        return seg_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "af759940",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved output to /home/pdhegde/semseg_git_fork/semantic-segmentation/out/1721394059_Camera0_visible.png\n",
      "Saved output to /home/pdhegde/semseg_git_fork/semantic-segmentation/out/1721394070_Camera0_visible.png\n",
      "Saved output to /home/pdhegde/semseg_git_fork/semantic-segmentation/out/1721394097_Camera0_visible.png\n",
      "Saved output to /home/pdhegde/semseg_git_fork/semantic-segmentation/out/1721394072_Camera0_visible.png\n",
      "Saved output to /home/pdhegde/semseg_git_fork/semantic-segmentation/out/1721394064_Camera0_visible.png\n",
      "Saved output to /home/pdhegde/semseg_git_fork/semantic-segmentation/out/1721394076_Camera0_visible.png\n",
      "Saved output to /home/pdhegde/semseg_git_fork/semantic-segmentation/out/1721394082_Camera0_visible.png\n",
      "Saved output to /home/pdhegde/semseg_git_fork/semantic-segmentation/out/1721394098_Camera0_visible.png\n",
      "Saved output to /home/pdhegde/semseg_git_fork/semantic-segmentation/out/1721394088_Camera0_visible.png\n",
      "Saved output to /home/pdhegde/semseg_git_fork/semantic-segmentation/out/1721394086_Camera0_visible.png\n",
      "Saved output to /home/pdhegde/semseg_git_fork/semantic-segmentation/out/1721394078_Camera0_visible.png\n",
      "Saved output to /home/pdhegde/semseg_git_fork/semantic-segmentation/out/1721394068_Camera0_visible.png\n"
     ]
    }
   ],
   "source": [
    "generate_inference(config, output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23012752",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a77ffe759bda3d3567daded5bac300ead598ab956e5dd122484d239362fc3155"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('semantic-segmentation')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
